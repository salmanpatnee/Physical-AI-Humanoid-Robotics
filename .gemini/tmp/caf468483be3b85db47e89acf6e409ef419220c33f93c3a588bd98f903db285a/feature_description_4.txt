The system should read the book (PDF or docs/) and produce searchable text chunks with identifiers and basic metadata (document, page, chunk_id), then generate vector embeddings for each chunk and store them in a hosted vector database. Acceptance: chunks + embeddings exist for the whole book and a sample similarity query returns relevant chunk IDs. Context: Integrated RAG Chatbot Development: Build and embed a Retrieval-Augmented Generation (RAG) chatbot within the published book. This chatbot, utilizing the OpenAI Agents/ChatKit SDKs, FastAPI, Neon Serverless Postgres database, and Qdrant Cloud Free Tier, must be able to answer user questions about the book's content, including answering questions based only on text selected by the user.