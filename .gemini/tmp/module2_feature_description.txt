Module 2 will introduce readers to the concept of a 'Digital Twin' by teaching how humanoid robots are simulated inside physics-accurate virtual environments using Gazebo and Unity, written using Docusaurus MDX with the same structured learning components as Module 1. This module will explain how modern humanoid systems rely on high-fidelity digital replicas to test locomotion, articulation, perception, and interaction before deploying to real hardware. Students will learn how to simulate rigid-body physics, gravity, collisions, and sensor data streams in Gazebo, and how Unity provides photorealistic rendering for human-robot interaction scenarios. The chapter will also teach how to simulate LiDAR, Depth Cameras, and IMUs, and show how sensor noise, latency, and frame alignment affect embodied AI performance. All content will use the textbook’s MDX components—<LearningObjectives />, <KeyTakeaways />, <Prerequisites />, and <ExerciseBlock />—and will include frontmatter metadata validated against the project’s JSON Schema during the Docusaurus build. Module output includes physics demonstrations, Gazebo world files, Unity scenes, simulated sensor diagrams, and guided exercises that walk students through building, launching, and debugging a digital twin of a humanoid robot. Module 2 heading will be The Digital Twin (Gazebo & Unity) and topics or chapters are 1 – Focus: Physics simulation and world building. 2 – Simulating collisions, gravity, and sensors in Gazebo. 3 – High-fidelity rendering and interaction scenes in Unity. 4 – Sensor simulation: LiDAR, Depth Cameras, and IMUs